<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Abdul Waheed</title>

    <meta name="author" content="Abdul Waheed">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

    <script>
      // Function to update the date dynamically
      document.addEventListener("DOMContentLoaded", function() {
        const lastUpdatedElement = document.getElementById('last-updated');
        const options = { year: 'numeric', month: 'long', day: 'numeric' };
        const today = new Date().toLocaleDateString(undefined, options);
        lastUpdatedElement.textContent = `Last updated: ${today}`;
      });
    </script>
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Abdul Waheed
                </p>
                <p>I'm a grad student at <a href="https://www.cmu.edu/">School of Computer Science, Carnegie Mellon University</a> in Pittsburgh, PA.</p>
                </p>
                <p>
                  <!-- At Google I've worked on <a href="https://www.google.com/glass/start/">Glass</a>,  <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">VR</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, and <a href="https://blog.google/products/maps/three-maps-updates-io-2022/">Maps</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>. I've received the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>. -->
                </p>
                <p style="text-align:center">
                  <a href="mailto:abdulwaheed1513@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=I0hRiBYAAAAJ&view_op=list_works&sortby=pubdate">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/MacAbdul9">Twitter/X</a> &nbsp;/&nbsp;
                  <a href="https://github.com/macabdul9">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/abdulwaheed.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/abdulwaheed.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I am interested in robust and interpretable machine learning. Please find some of my work below and visit my google scholar for more details.</span>
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2><font size="5">Updates</h2>
                <font size="3"><li><strong> Feb 2025 </strong> Excited to release two new preprints on <a href="https://arxiv.org/abs/2502.12408">Approximating ASR Metrics</a> and <a href="https://arxiv.org/abs/2502.12414">Demystifying Hallucination in Speech Foundation Models</a></li></font>
                <font size="3"><li><strong>Jan 2025</strong> - <a href="https://arxiv.org/abs/2407.01257v3">uDistil-Whisper</a> was accepted at <a href="https://2025.naacl.org/">NAACL'2025</a> main.</li>
                <font size="3"><li><strong>Oct 2024</strong> - Excited to release three new preprints of our work on <a href="https://arxiv.org/abs/2407.01257v3">Unsupervised Data Filtering For Knowledge Distillation</a>, <a href="https://arxiv.org/abs/2410.12948">Investigating What Speech Foundation Models Learn About Speech</a>, and <a href="https://arxiv.org/abs/2410.15226">Synthetic Data for LLM Pretraining</a>.</li>
                <font size="3"><li><strong>August 2024</strong> - Joined LTI@CMU as graduate student.</li>
                <font size="3"><li><strong>June 2024</strong> - 1 main + 1 workshop papers accepted at ACL'2024.</li>
                <font size="3"><li>Old updates are archived.</li>
            </td>
          </tr>
        </tbody></table>
      
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <h2><font size="5"> Publications</h2> </font>
            <p>* <font size="3"> denotes equal contribution / first co-authors</p>
            <p> Please visit scholar page for more details.</p>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      
        <table>
          <tbody>
            <!-- Publication 13 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/hallucination.png" alt="Demystifying Hallucination in Speech Foundation Models" width="220" height="130">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle" style="font-weight: normal;" style="font-weight: normal;"><font size="3">Lost in Transcription, Found in Distribution Shift: Demystifying Hallucination in Speech Foundation Models
                </font></span>
                <br>
                Hanin Atwany*, <strong><font size="3">Abdul Waheed*</font></strong>, Rita Singh, Monojit Choudhury, Bhiksha Raj
                <br>
                <strong><em><font size="3">Preprint</font>, 2025</em></strong>
                <br>
                <a href="https://arxiv.org/abs/2502.12414"><font size="3">Paper</font></a>
                <p></p>
              </td>

            <!-- Publication 12 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/asr_metrics.png" alt="Approximating ASR Metrics" width="220" height="130">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle" style="font-weight: normal;" style="font-weight: normal;"><font size="3">On the Robust Approximation of ASR Metrics
                </font></span>
                <br>
                <strong><font size="3">Abdul Waheed</font></strong>, Hanin Atwany, Rita Singh, Bhiksha Raj
                <br>
                <strong><em><font size="3">Preprint</font>, 2025</em></strong>
                <br>
                <a href="https://arxiv.org/abs/2502.12408"><font size="3">Paper</font></a>
                <p></p>
              </td>

            <!-- Publication 11 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/synthdiversity.png" alt="uDistil-Whisper" width="220" height="130">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle" style="font-weight: normal;" style="font-weight: normal;"><font size="3">On the Diversity of Synthetic Data and its Impact on Training Large Language Models</font></span>
                <br>
                Hao Chen, <strong><font size="3">Abdul Waheed</font></strong>, Xiang Li, Yidong Wang, Jindong Wang, Bhiksha Raj, Marah I. Abdin
                <br>
                <strong><em><font size="3">Preprint</font>, 2024</em></strong>
                <br>
                <a href="https://arxiv.org/abs/2410.15226"><font size="3">Paper</font></a>
                <p></p>
              </td>
            </tr>


            <!-- Publication 10 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/sfmprobing.png" alt="uDistil-Whisper" width="220" height="130">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle" style="font-weight: normal;" style="font-weight: normal;"><font size="3">What Do Speech Foundation Models Not Learn About Speech?</font></span>
                <br>
                <strong><font size="3">Abdul Waheed</font></strong>, Hanin Atwany, Bhiksha Raj, Rita Singh
                <br>
                <strong><em><font size="3">Preprint</font>, 2024</em></strong>
                <br>
                <a href="https://arxiv.org/abs/2410.12948"><font size="3">Paper</font></a>
                <p></p>
              </td>
            </tr>

            <!-- Publication 9 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/udistil_whisper.png" alt="uDistil-Whisper" width="220" height="130">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle" style="font-weight: normal;" style="font-weight: normal;"><font size="3">uDistil-Whisper: Label-Free Data Filtering for Knowledge Distillation in Low-Data Regimes</font></span>
                <br>
                <strong><font size="3">Abdul Waheed</font></strong>, Karima Kadaoui, Muhammad Abdul-Mageed
                <br>
                <strong><em><font size="3">NAACL Main</font>, 2025</em></strong>
                <br>
                <a href="https://arxiv.org/abs/2407.01257v3"><font size="3">Paper</font></a>
                <p></p>
              </td>
            </tr>
            
            <!-- Publication 8 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/robust_distillation.png" alt="Robust Knowledge Distillation" width="220" height="130">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle" style="font-weight: normal;"><font size="3">To Distill or Not to Distill? On the Robustness of Robust Knowledge Distillation</font></span>
                <br>
                <strong><font size="3">Abdul Waheed</font></strong>, Karima Kadaoui, Muhammad Abdul-Mageed
                <br>
                <strong><em><font size="3">ACL Main</font>, 2024</em></strong>
                <br>
                <a href="https://aclanthology.org/2024.acl-long.680/"><font size="3">Paper</font></a>
                |
                <a href="https://huggingface.co/collections/distil-whisper-ar/distil-whisper-arabic-65cf157cd82f8d722c89391c"><font size="3">Models</font></a>
                <p></p>
              </td>
            </tr>
        
            <!-- Publication 7 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/towards_zero_shot_tts.png" alt="Zero-Shot TTS" width="220" height="130">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle" style="font-weight: normal;"><font size="3">Towards Zero-Shot Text-To-Speech for Arabic Dialects</font></span>
                <br>
                Khai Duy Doan, <strong><font size="3">Abdul Waheed</font></strong>, Muhammad Abdul-Mageed
                <br>
                <strong><em><font size="3">ArabicNLP conference co-located with ACL </font>, 2024</em></strong>
                <br>
                <a href="https://arxiv.org/abs/2406.16751"><font size="3">Paper</font></a>
                <p></p>
              </td>
            </tr>

            <!-- Publication 6 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/lamini_lm.png" alt="LaMini-LM" width="220" height="130">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle" style="font-weight: normal;"><font size="3">LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions</font></span>
                <br>
                Minghao Wu, <strong><font size="3">Abdul Waheed</font></strong>, Chiyu Zhang, Muhammad Abdul-Mageed, Alham Fikri Aji
                <br>
                <strong><em><font size="3">EACL Main</font>, 2024</em></strong>
                <br>
                <a href="https://aclanthology.org/2024.eacl-long.57/"><font size="3">Paper</font></a>
                |
                <a href="https://github.com/mbzuai-nlp/LaMini-LM"><font size="3">Models</font></a>
                |
                <a href="https://github.com/mbzuai-nlp/LaMini-LM"><font size="3">Data</font></a>
                <p></p>
              </td>
            </tr>

            <!-- Publication 5 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/gptaraeval.png" alt="GPTaraeval" width="220" height="130">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle" style="font-weight: normal;"><font size="3">GPTAraEval: A Comprehensive Evaluation of ChatGPT on Arabic NLP</font></span>
                <br>
                Md Tawkat Islam Khondaker, <strong><font size="3">Abdul Waheed</font></strong>, El Moatez Billah Nagoudi, Muhammad Abdul-Mageed
                <br>
                <strong><em><font size="3">EMNLP Main</font>, 2023</em></strong>
                <br>
                <a href="https://aclanthology.org/2023.emnlp-main.16/"><font size="3">Paper</font></a>
                <p></p>
              </td>
            </tr>
        
            <!-- Publication 4 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/tarjamat.png" alt="Tarjamat" width="220" height="130">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle" style="font-weight: normal;"><font size="3">TARJAMAT: Evaluation of Bard and ChatGPT on Machine Translation of Ten Arabic Varieties</font></span>
                <br>
                Karima Kadaoui*, Samar M. Magdy*, <strong><font size="3">Abdul Waheed*</font></strong>, Md Tawkat Islam Khondaker, Ahmed Oumar El-Shangiti, El Moatez Billah Nagoudi, Muhammad Abdul-Mageed
                <br>
                <strong><em><font size="3">ArabicNLP conference co-located with EMNLP</font>, 2023</em></strong>
                <br>
                <a href="https://aclanthology.org/2023.arabicnlp-1.6/"><font size="3">Paper</font></a>
                <p></p>
              </td>
            </tr>

            <!-- Publication 3 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/whisper_arabic.png" alt="Whisper Arabic" width="220" height="130">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle" style="font-weight: normal;"><font size="3">N-Shot Benchmarking of Whisper on Diverse Arabic Speech Recognition</font></span>
                <br>
                Bashar Talafha*, <strong><font size="3">Abdul Waheed*</font></strong>, Muhammad Abdul-Mageed
                <br>
                <strong><em><font size="3">Interspeech, 2023</font></em></strong>
                <br>
                <a href="https://www.isca-archive.org/interspeech_2023/talafha23_interspeech.pdf"><font size="3">Paper</font></a>
                |
                <a href="https://github.com/macabdul9/N-Shot-Benchmarking-of-Whisper"><font size="3">Code</font></a>
                <p></p>
              </td>
            </tr>
        
            <!-- Publication 2 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/dialogue_act_classification.png" alt="Dialogue Act Classification" width="220" height="130">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle" style="font-weight: normal;"><font size="3">Speaker and Time-aware Joint Contextual Learning for Dialogue-act Classification in Counselling Conversations</font></span>
                <br>
                Ganeshan Malhotra, <strong><font size="3">Abdul Waheed</font></strong>, Aseem Srivastava, Md Shad Akhtar, Tanmoy Chakraborty
                <br>
                <strong><em><font size="3">ACM International Conference on Web Search and Data Mining (WSDM)</font>, 2022</em></strong>
                <br>
                <a href="https://arxiv.org/abs/2111.06647"><font size="3">Paper</font></a>
                <p></p>
              </td>
            </tr>

            <!-- Publication 1 -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/domain_robustness.png" alt="Domain Robustness of Pretrained Models" width="220" height="130">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle" style="font-weight: normal;"><font size="3">Analyzing the Domain Robustness of Pretrained Language Models, Layer by Layer</font></span>
                <br>
                Abhinav Ramesh Kashyap, Laiba Mehnaz, Bhavitvya Malik, <strong><font size="3">Abdul Waheed</font></strong>, Devamanyu Hazarika, Min-Yen Kan, Rajiv Shah
                <br>
                <strong><em><font size="3">Domain Adaptation for NLP workshop co-located with EACL</font>, 2021</em></strong>
                <br>
                <a href="https://aclanthology.org/2021.adaptnlp-1.23/"><font size="3">Paper</font></a>
                <p></p>
              </td>
            </tr>

          </tbody>
        </table>
                    
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Fork from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's website</a>.
                </p>
              </td>
            </tr>
            <!-- Last updated row -->
            <tr>
            <!-- <td style="padding:0px;text-align:center;font-size:small;" id="last-updated"> -->
              <!-- The JavaScript will automatically insert the current date here -->
            </td>
          </tr>

          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
